{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nX = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/train.csv', index_col='Id')\nX_test_full = pd.read_csv('/kaggle/input/house-prices-advanced-regression-techniques/test.csv', index_col='Id')\ntest_data = pd.read_csv(\"/kaggle/input/house-prices-advanced-regression-techniques/test.csv\")\n# Remove rows with missing target, separate target from predictors\n\n\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X.SalePrice\nX.drop(['SalePrice'], axis=1, inplace=True)\n\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# \"Cardinality\" means the number of unique values in a column\n# Select categorical columns with relatively low cardinality (convenient but arbitrary)\nlow_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n                        X_train_full[cname].dtype == \"object\"]\n\n# Select numeric columns\nnumeric_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]\nscaler = MinMaxScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n# Keep selected columns only\nmy_cols = low_cardinality_cols + numeric_cols\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = X_test_full[my_cols].copy()\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T20:33:19.389515Z","iopub.execute_input":"2022-07-26T20:33:19.390018Z","iopub.status.idle":"2022-07-26T20:33:19.658076Z","shell.execute_reply.started":"2022-07-26T20:33:19.389978Z","shell.execute_reply":"2022-07-26T20:33:19.656769Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"input_shape = [X_train.shape[1]]\nprint(input_shape)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T20:33:23.165927Z","iopub.execute_input":"2022-07-26T20:33:23.166457Z","iopub.status.idle":"2022-07-26T20:33:23.174107Z","shell.execute_reply.started":"2022-07-26T20:33:23.166421Z","shell.execute_reply":"2022-07-26T20:33:23.172625Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stdout","text":"[227]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\n\n# YOUR CODE HERE: define the model given in the diagram\nmodel = keras.Sequential([layers.BatchNormalization(input_shape = input_shape),\n                          layers.Dense(256, activation = 'relu'),\n                          layers.BatchNormalization(),\n                          layers.Dropout(0.3),\n                          layers.Dense(256, activation = 'relu'),\n                          layers.BatchNormalization(),\n                          layers.Dropout(0.3),\n                          layers.Dense(1, activation = 'sigmoid')])\n","metadata":{"execution":{"iopub.status.busy":"2022-07-26T20:33:28.034931Z","iopub.execute_input":"2022-07-26T20:33:28.035356Z","iopub.status.idle":"2022-07-26T20:33:28.146671Z","shell.execute_reply.started":"2022-07-26T20:33:28.035316Z","shell.execute_reply":"2022-07-26T20:33:28.144600Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam',\n    loss='binary_crossentropy',\n    metrics=['binary_accuracy'],)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T20:33:31.755366Z","iopub.execute_input":"2022-07-26T20:33:31.756253Z","iopub.status.idle":"2022-07-26T20:33:31.767885Z","shell.execute_reply.started":"2022-07-26T20:33:31.756213Z","shell.execute_reply":"2022-07-26T20:33:31.766568Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    patience=5,\n    min_delta=0.001,\n    restore_best_weights=True,\n)\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_valid, y_valid),\n    batch_size=512,\n    epochs=200,\n    callbacks=[early_stopping],\n)\nprediction = model.predict(X_test)\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2022-07-26T20:33:38.390635Z","iopub.execute_input":"2022-07-26T20:33:38.391205Z","iopub.status.idle":"2022-07-26T20:33:58.279925Z","shell.execute_reply.started":"2022-07-26T20:33:38.391167Z","shell.execute_reply":"2022-07-26T20:33:58.278603Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Epoch 1/200\n3/3 [==============================] - 2s 176ms/step - loss: -2677.0171 - binary_accuracy: 0.0000e+00 - val_loss: -12092.5498 - val_binary_accuracy: 0.0000e+00\nEpoch 2/200\n3/3 [==============================] - 0s 33ms/step - loss: -14903.7842 - binary_accuracy: 0.0000e+00 - val_loss: -24944.5781 - val_binary_accuracy: 0.0000e+00\nEpoch 3/200\n3/3 [==============================] - 0s 36ms/step - loss: -27916.7539 - binary_accuracy: 0.0000e+00 - val_loss: -38674.5156 - val_binary_accuracy: 0.0000e+00\nEpoch 4/200\n3/3 [==============================] - 0s 34ms/step - loss: -41838.8281 - binary_accuracy: 0.0000e+00 - val_loss: -53369.7031 - val_binary_accuracy: 0.0000e+00\nEpoch 5/200\n3/3 [==============================] - 0s 38ms/step - loss: -56663.4648 - binary_accuracy: 0.0000e+00 - val_loss: -69118.9922 - val_binary_accuracy: 0.0000e+00\nEpoch 6/200\n3/3 [==============================] - 0s 34ms/step - loss: -72697.6875 - binary_accuracy: 0.0000e+00 - val_loss: -85992.5234 - val_binary_accuracy: 0.0000e+00\nEpoch 7/200\n3/3 [==============================] - 0s 39ms/step - loss: -89611.8125 - binary_accuracy: 0.0000e+00 - val_loss: -104063.1406 - val_binary_accuracy: 0.0000e+00\nEpoch 8/200\n3/3 [==============================] - 0s 38ms/step - loss: -107743.0312 - binary_accuracy: 0.0000e+00 - val_loss: -123434.6875 - val_binary_accuracy: 0.0000e+00\nEpoch 9/200\n3/3 [==============================] - 0s 38ms/step - loss: -128103.2344 - binary_accuracy: 0.0000e+00 - val_loss: -144180.4688 - val_binary_accuracy: 0.0000e+00\nEpoch 10/200\n3/3 [==============================] - 0s 36ms/step - loss: -148836.5938 - binary_accuracy: 0.0000e+00 - val_loss: -166344.6719 - val_binary_accuracy: 0.0000e+00\nEpoch 11/200\n3/3 [==============================] - 0s 36ms/step - loss: -171367.8438 - binary_accuracy: 0.0000e+00 - val_loss: -189976.3906 - val_binary_accuracy: 0.0000e+00\nEpoch 12/200\n3/3 [==============================] - 0s 34ms/step - loss: -194890.7969 - binary_accuracy: 0.0000e+00 - val_loss: -215139.9844 - val_binary_accuracy: 0.0000e+00\nEpoch 13/200\n3/3 [==============================] - 0s 36ms/step - loss: -220862.4531 - binary_accuracy: 0.0000e+00 - val_loss: -241924.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 14/200\n3/3 [==============================] - 0s 35ms/step - loss: -248087.0469 - binary_accuracy: 0.0000e+00 - val_loss: -270359.3125 - val_binary_accuracy: 0.0000e+00\nEpoch 15/200\n3/3 [==============================] - 0s 31ms/step - loss: -276326.6875 - binary_accuracy: 0.0000e+00 - val_loss: -300529.1875 - val_binary_accuracy: 0.0000e+00\nEpoch 16/200\n3/3 [==============================] - 0s 67ms/step - loss: -307358.6250 - binary_accuracy: 0.0000e+00 - val_loss: -332475.0625 - val_binary_accuracy: 0.0000e+00\nEpoch 17/200\n3/3 [==============================] - 0s 34ms/step - loss: -339146.6250 - binary_accuracy: 0.0000e+00 - val_loss: -366192.3438 - val_binary_accuracy: 0.0000e+00\nEpoch 18/200\n3/3 [==============================] - 0s 33ms/step - loss: -373288.0000 - binary_accuracy: 0.0000e+00 - val_loss: -401726.0938 - val_binary_accuracy: 0.0000e+00\nEpoch 19/200\n3/3 [==============================] - 0s 31ms/step - loss: -409359.5312 - binary_accuracy: 0.0000e+00 - val_loss: -439189.6875 - val_binary_accuracy: 0.0000e+00\nEpoch 20/200\n3/3 [==============================] - 0s 33ms/step - loss: -446187.9375 - binary_accuracy: 0.0000e+00 - val_loss: -478516.8125 - val_binary_accuracy: 0.0000e+00\nEpoch 21/200\n3/3 [==============================] - 0s 31ms/step - loss: -486029.0312 - binary_accuracy: 0.0000e+00 - val_loss: -519796.9375 - val_binary_accuracy: 0.0000e+00\nEpoch 22/200\n3/3 [==============================] - 0s 31ms/step - loss: -527069.3750 - binary_accuracy: 0.0000e+00 - val_loss: -562969.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 23/200\n3/3 [==============================] - 0s 33ms/step - loss: -570933.1250 - binary_accuracy: 0.0000e+00 - val_loss: -608157.1875 - val_binary_accuracy: 0.0000e+00\nEpoch 24/200\n3/3 [==============================] - 0s 32ms/step - loss: -615360.1875 - binary_accuracy: 0.0000e+00 - val_loss: -655212.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 25/200\n3/3 [==============================] - 0s 30ms/step - loss: -663990.7500 - binary_accuracy: 0.0000e+00 - val_loss: -704156.0625 - val_binary_accuracy: 0.0000e+00\nEpoch 26/200\n3/3 [==============================] - 0s 31ms/step - loss: -715180.5000 - binary_accuracy: 0.0000e+00 - val_loss: -755162.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 27/200\n3/3 [==============================] - 0s 31ms/step - loss: -765037.6875 - binary_accuracy: 0.0000e+00 - val_loss: -808277.8125 - val_binary_accuracy: 0.0000e+00\nEpoch 28/200\n3/3 [==============================] - 0s 32ms/step - loss: -816246.0000 - binary_accuracy: 0.0000e+00 - val_loss: -863248.8750 - val_binary_accuracy: 0.0000e+00\nEpoch 29/200\n3/3 [==============================] - 0s 32ms/step - loss: -873011.3750 - binary_accuracy: 0.0000e+00 - val_loss: -920204.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 30/200\n3/3 [==============================] - 0s 30ms/step - loss: -931186.4375 - binary_accuracy: 0.0000e+00 - val_loss: -979364.3750 - val_binary_accuracy: 0.0000e+00\nEpoch 31/200\n3/3 [==============================] - 0s 32ms/step - loss: -989336.5625 - binary_accuracy: 0.0000e+00 - val_loss: -1040596.6250 - val_binary_accuracy: 0.0000e+00\nEpoch 32/200\n3/3 [==============================] - 0s 32ms/step - loss: -1050585.5000 - binary_accuracy: 0.0000e+00 - val_loss: -1104060.1250 - val_binary_accuracy: 0.0000e+00\nEpoch 33/200\n3/3 [==============================] - 0s 33ms/step - loss: -1115182.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1169583.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 34/200\n3/3 [==============================] - 0s 42ms/step - loss: -1181013.7500 - binary_accuracy: 0.0000e+00 - val_loss: -1237270.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 35/200\n3/3 [==============================] - 0s 33ms/step - loss: -1248268.2500 - binary_accuracy: 0.0000e+00 - val_loss: -1307310.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 36/200\n3/3 [==============================] - 0s 33ms/step - loss: -1323515.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1379818.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 37/200\n3/3 [==============================] - 0s 31ms/step - loss: -1394885.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1454585.3750 - val_binary_accuracy: 0.0000e+00\nEpoch 38/200\n3/3 [==============================] - 0s 31ms/step - loss: -1464722.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1531295.8750 - val_binary_accuracy: 0.0000e+00\nEpoch 39/200\n3/3 [==============================] - 0s 32ms/step - loss: -1546182.5000 - binary_accuracy: 0.0000e+00 - val_loss: -1610223.8750 - val_binary_accuracy: 0.0000e+00\nEpoch 40/200\n3/3 [==============================] - 0s 34ms/step - loss: -1624295.2500 - binary_accuracy: 0.0000e+00 - val_loss: -1691493.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 41/200\n3/3 [==============================] - 0s 34ms/step - loss: -1708433.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1774882.3750 - val_binary_accuracy: 0.0000e+00\nEpoch 42/200\n3/3 [==============================] - 0s 32ms/step - loss: -1788829.3750 - binary_accuracy: 0.0000e+00 - val_loss: -1860313.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 43/200\n3/3 [==============================] - 0s 35ms/step - loss: -1871537.5000 - binary_accuracy: 0.0000e+00 - val_loss: -1948084.3750 - val_binary_accuracy: 0.0000e+00\nEpoch 44/200\n3/3 [==============================] - 0s 31ms/step - loss: -1963077.8750 - binary_accuracy: 0.0000e+00 - val_loss: -2037959.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 45/200\n3/3 [==============================] - 0s 31ms/step - loss: -2050068.1250 - binary_accuracy: 0.0000e+00 - val_loss: -2130178.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 46/200\n3/3 [==============================] - 0s 32ms/step - loss: -2140076.7500 - binary_accuracy: 0.0000e+00 - val_loss: -2224815.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 47/200\n3/3 [==============================] - 0s 36ms/step - loss: -2240257.7500 - binary_accuracy: 0.0000e+00 - val_loss: -2321510.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 48/200\n3/3 [==============================] - 0s 33ms/step - loss: -2335225.5000 - binary_accuracy: 0.0000e+00 - val_loss: -2420267.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 49/200\n3/3 [==============================] - 0s 33ms/step - loss: -2437076.0000 - binary_accuracy: 0.0000e+00 - val_loss: -2521040.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 50/200\n3/3 [==============================] - 0s 31ms/step - loss: -2539297.2500 - binary_accuracy: 0.0000e+00 - val_loss: -2624027.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 51/200\n3/3 [==============================] - 0s 32ms/step - loss: -2636846.5000 - binary_accuracy: 0.0000e+00 - val_loss: -2729035.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 52/200\n3/3 [==============================] - 0s 33ms/step - loss: -2742119.2500 - binary_accuracy: 0.0000e+00 - val_loss: -2835920.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 53/200\n3/3 [==============================] - 0s 37ms/step - loss: -2857918.0000 - binary_accuracy: 0.0000e+00 - val_loss: -2945347.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 54/200\n3/3 [==============================] - 0s 33ms/step - loss: -2958164.5000 - binary_accuracy: 0.0000e+00 - val_loss: -3057258.7500 - val_binary_accuracy: 0.0000e+00\nEpoch 55/200\n3/3 [==============================] - 0s 33ms/step - loss: -3069001.7500 - binary_accuracy: 0.0000e+00 - val_loss: -3171260.7500 - val_binary_accuracy: 0.0000e+00\nEpoch 56/200\n3/3 [==============================] - 0s 32ms/step - loss: -3187961.5000 - binary_accuracy: 0.0000e+00 - val_loss: -3287352.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 57/200\n3/3 [==============================] - 0s 31ms/step - loss: -3300259.0000 - binary_accuracy: 0.0000e+00 - val_loss: -3405882.7500 - val_binary_accuracy: 0.0000e+00\nEpoch 58/200\n3/3 [==============================] - 0s 32ms/step - loss: -3431230.0000 - binary_accuracy: 0.0000e+00 - val_loss: -3526704.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 59/200\n3/3 [==============================] - 0s 32ms/step - loss: -3543082.0000 - binary_accuracy: 0.0000e+00 - val_loss: -3650221.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 60/200\n3/3 [==============================] - 0s 36ms/step - loss: -3664863.0000 - binary_accuracy: 0.0000e+00 - val_loss: -3775814.2500 - val_binary_accuracy: 0.0000e+00\nEpoch 61/200\n3/3 [==============================] - 0s 36ms/step - loss: -3796775.5000 - binary_accuracy: 0.0000e+00 - val_loss: -3903516.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 62/200\n3/3 [==============================] - 0s 34ms/step - loss: -3920866.2500 - binary_accuracy: 0.0000e+00 - val_loss: -4033625.7500 - val_binary_accuracy: 0.0000e+00\nEpoch 63/200\n3/3 [==============================] - 0s 36ms/step - loss: -4059366.5000 - binary_accuracy: 0.0000e+00 - val_loss: -4166400.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 64/200\n3/3 [==============================] - 0s 35ms/step - loss: -4191181.2500 - binary_accuracy: 0.0000e+00 - val_loss: -4301339.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 65/200\n3/3 [==============================] - 0s 34ms/step - loss: -4324562.5000 - binary_accuracy: 0.0000e+00 - val_loss: -4438604.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 66/200\n3/3 [==============================] - 0s 36ms/step - loss: -4454722.0000 - binary_accuracy: 0.0000e+00 - val_loss: -4578359.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 67/200\n3/3 [==============================] - 0s 34ms/step - loss: -4602352.0000 - binary_accuracy: 0.0000e+00 - val_loss: -4720877.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 68/200\n3/3 [==============================] - 0s 33ms/step - loss: -4735213.0000 - binary_accuracy: 0.0000e+00 - val_loss: -4865346.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 69/200\n3/3 [==============================] - 0s 33ms/step - loss: -4881201.5000 - binary_accuracy: 0.0000e+00 - val_loss: -5012363.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 70/200\n3/3 [==============================] - 0s 30ms/step - loss: -5029223.5000 - binary_accuracy: 0.0000e+00 - val_loss: -5161689.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 71/200\n3/3 [==============================] - 0s 31ms/step - loss: -5186122.0000 - binary_accuracy: 0.0000e+00 - val_loss: -5313197.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 72/200\n3/3 [==============================] - 0s 30ms/step - loss: -5333753.5000 - binary_accuracy: 0.0000e+00 - val_loss: -5466758.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 73/200\n3/3 [==============================] - 0s 39ms/step - loss: -5485939.0000 - binary_accuracy: 0.0000e+00 - val_loss: -5622563.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 74/200\n3/3 [==============================] - 0s 30ms/step - loss: -5642267.0000 - binary_accuracy: 0.0000e+00 - val_loss: -5780493.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 75/200\n3/3 [==============================] - 0s 32ms/step - loss: -5802335.5000 - binary_accuracy: 0.0000e+00 - val_loss: -5940499.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 76/200\n3/3 [==============================] - 0s 30ms/step - loss: -5946020.0000 - binary_accuracy: 0.0000e+00 - val_loss: -6102397.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 77/200\n3/3 [==============================] - 0s 31ms/step - loss: -6118559.5000 - binary_accuracy: 0.0000e+00 - val_loss: -6266600.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 78/200\n3/3 [==============================] - 0s 32ms/step - loss: -6289464.5000 - binary_accuracy: 0.0000e+00 - val_loss: -6433145.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 79/200\n3/3 [==============================] - 0s 32ms/step - loss: -6455694.0000 - binary_accuracy: 0.0000e+00 - val_loss: -6601935.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 80/200\n3/3 [==============================] - 0s 35ms/step - loss: -6628834.5000 - binary_accuracy: 0.0000e+00 - val_loss: -6773322.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 81/200\n3/3 [==============================] - 0s 37ms/step - loss: -6794433.0000 - binary_accuracy: 0.0000e+00 - val_loss: -6946569.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 82/200\n3/3 [==============================] - 0s 34ms/step - loss: -6961664.0000 - binary_accuracy: 0.0000e+00 - val_loss: -7121942.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 83/200\n3/3 [==============================] - 0s 34ms/step - loss: -7138956.5000 - binary_accuracy: 0.0000e+00 - val_loss: -7299777.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 84/200\n3/3 [==============================] - 0s 33ms/step - loss: -7321215.0000 - binary_accuracy: 0.0000e+00 - val_loss: -7479795.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 85/200\n3/3 [==============================] - 0s 35ms/step - loss: -7490371.5000 - binary_accuracy: 0.0000e+00 - val_loss: -7662020.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 86/200\n3/3 [==============================] - 0s 35ms/step - loss: -7676702.0000 - binary_accuracy: 0.0000e+00 - val_loss: -7846654.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 87/200\n3/3 [==============================] - 0s 34ms/step - loss: -7882030.5000 - binary_accuracy: 0.0000e+00 - val_loss: -8033934.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 88/200\n3/3 [==============================] - 0s 34ms/step - loss: -8047106.0000 - binary_accuracy: 0.0000e+00 - val_loss: -8223547.5000 - val_binary_accuracy: 0.0000e+00\nEpoch 89/200\n3/3 [==============================] - 0s 34ms/step - loss: -8249553.5000 - binary_accuracy: 0.0000e+00 - val_loss: -8415305.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 90/200\n3/3 [==============================] - 0s 35ms/step - loss: -8458933.0000 - binary_accuracy: 0.0000e+00 - val_loss: -8609313.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 91/200\n3/3 [==============================] - 0s 34ms/step - loss: -8629752.0000 - binary_accuracy: 0.0000e+00 - val_loss: -8805610.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 92/200\n3/3 [==============================] - 0s 32ms/step - loss: -8825925.0000 - binary_accuracy: 0.0000e+00 - val_loss: -9004260.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 93/200\n3/3 [==============================] - 0s 36ms/step - loss: -9027675.0000 - binary_accuracy: 0.0000e+00 - val_loss: -9204745.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 94/200\n3/3 [==============================] - 0s 33ms/step - loss: -9216465.0000 - binary_accuracy: 0.0000e+00 - val_loss: -9406909.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 95/200\n3/3 [==============================] - 0s 34ms/step - loss: -9408366.0000 - binary_accuracy: 0.0000e+00 - val_loss: -9610962.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 96/200\n3/3 [==============================] - 0s 31ms/step - loss: -9648329.0000 - binary_accuracy: 0.0000e+00 - val_loss: -9817639.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 97/200\n3/3 [==============================] - 0s 33ms/step - loss: -9828233.0000 - binary_accuracy: 0.0000e+00 - val_loss: -10027165.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 98/200\n3/3 [==============================] - 0s 33ms/step - loss: -10055131.0000 - binary_accuracy: 0.0000e+00 - val_loss: -10238853.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 99/200\n3/3 [==============================] - 0s 33ms/step - loss: -10250374.0000 - binary_accuracy: 0.0000e+00 - val_loss: -10452830.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 100/200\n3/3 [==============================] - 0s 33ms/step - loss: -10478662.0000 - binary_accuracy: 0.0000e+00 - val_loss: -10669190.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 101/200\n3/3 [==============================] - 0s 37ms/step - loss: -10704884.0000 - binary_accuracy: 0.0000e+00 - val_loss: -10887703.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 102/200\n3/3 [==============================] - 0s 35ms/step - loss: -10884410.0000 - binary_accuracy: 0.0000e+00 - val_loss: -11108057.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 103/200\n3/3 [==============================] - 0s 35ms/step - loss: -11141651.0000 - binary_accuracy: 0.0000e+00 - val_loss: -11330610.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 104/200\n3/3 [==============================] - 0s 34ms/step - loss: -11342076.0000 - binary_accuracy: 0.0000e+00 - val_loss: -11555106.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 105/200\n3/3 [==============================] - 0s 35ms/step - loss: -11563324.0000 - binary_accuracy: 0.0000e+00 - val_loss: -11782123.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 106/200\n3/3 [==============================] - 0s 34ms/step - loss: -11812227.0000 - binary_accuracy: 0.0000e+00 - val_loss: -12011236.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 107/200\n3/3 [==============================] - 0s 31ms/step - loss: -12040587.0000 - binary_accuracy: 0.0000e+00 - val_loss: -12242734.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 108/200\n3/3 [==============================] - 0s 31ms/step - loss: -12271886.0000 - binary_accuracy: 0.0000e+00 - val_loss: -12476556.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 109/200\n3/3 [==============================] - 0s 34ms/step - loss: -12499096.0000 - binary_accuracy: 0.0000e+00 - val_loss: -12712232.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 110/200\n3/3 [==============================] - 0s 33ms/step - loss: -12725179.0000 - binary_accuracy: 0.0000e+00 - val_loss: -12950210.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 111/200\n3/3 [==============================] - 0s 33ms/step - loss: -12953573.0000 - binary_accuracy: 0.0000e+00 - val_loss: -13189925.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 112/200\n3/3 [==============================] - 0s 30ms/step - loss: -13204368.0000 - binary_accuracy: 0.0000e+00 - val_loss: -13431203.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 113/200\n3/3 [==============================] - 0s 30ms/step - loss: -13437837.0000 - binary_accuracy: 0.0000e+00 - val_loss: -13674755.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 114/200\n3/3 [==============================] - 0s 30ms/step - loss: -13705657.0000 - binary_accuracy: 0.0000e+00 - val_loss: -13919734.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 115/200\n3/3 [==============================] - 0s 32ms/step - loss: -13960645.0000 - binary_accuracy: 0.0000e+00 - val_loss: -14167431.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 116/200\n3/3 [==============================] - 0s 33ms/step - loss: -14192463.0000 - binary_accuracy: 0.0000e+00 - val_loss: -14417939.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 117/200\n3/3 [==============================] - 0s 33ms/step - loss: -14452856.0000 - binary_accuracy: 0.0000e+00 - val_loss: -14670854.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 118/200\n3/3 [==============================] - 0s 33ms/step - loss: -14690707.0000 - binary_accuracy: 0.0000e+00 - val_loss: -14925999.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 119/200\n3/3 [==============================] - 0s 31ms/step - loss: -14947202.0000 - binary_accuracy: 0.0000e+00 - val_loss: -15183076.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 120/200\n3/3 [==============================] - 0s 30ms/step - loss: -15197344.0000 - binary_accuracy: 0.0000e+00 - val_loss: -15442814.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 121/200\n3/3 [==============================] - 0s 31ms/step - loss: -15456305.0000 - binary_accuracy: 0.0000e+00 - val_loss: -15705360.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 122/200\n3/3 [==============================] - 0s 31ms/step - loss: -15706997.0000 - binary_accuracy: 0.0000e+00 - val_loss: -15969669.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 123/200\n3/3 [==============================] - 0s 34ms/step - loss: -16007084.0000 - binary_accuracy: 0.0000e+00 - val_loss: -16236607.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 124/200\n3/3 [==============================] - 0s 30ms/step - loss: -16244596.0000 - binary_accuracy: 0.0000e+00 - val_loss: -16505824.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 125/200\n3/3 [==============================] - 0s 30ms/step - loss: -16522917.0000 - binary_accuracy: 0.0000e+00 - val_loss: -16777204.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 126/200\n3/3 [==============================] - 0s 34ms/step - loss: -16829974.0000 - binary_accuracy: 0.0000e+00 - val_loss: -17050934.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 127/200\n3/3 [==============================] - 0s 29ms/step - loss: -17061464.0000 - binary_accuracy: 0.0000e+00 - val_loss: -17326612.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 128/200\n3/3 [==============================] - 0s 29ms/step - loss: -17298452.0000 - binary_accuracy: 0.0000e+00 - val_loss: -17603776.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 129/200\n3/3 [==============================] - 0s 30ms/step - loss: -17664704.0000 - binary_accuracy: 0.0000e+00 - val_loss: -17883002.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 130/200\n3/3 [==============================] - 0s 31ms/step - loss: -17923740.0000 - binary_accuracy: 0.0000e+00 - val_loss: -18164706.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 131/200\n3/3 [==============================] - 0s 30ms/step - loss: -18184256.0000 - binary_accuracy: 0.0000e+00 - val_loss: -18447568.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 132/200\n3/3 [==============================] - 0s 33ms/step - loss: -18431236.0000 - binary_accuracy: 0.0000e+00 - val_loss: -18732532.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 133/200\n3/3 [==============================] - 0s 34ms/step - loss: -18735234.0000 - binary_accuracy: 0.0000e+00 - val_loss: -19019886.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 134/200\n3/3 [==============================] - 0s 31ms/step - loss: -18974686.0000 - binary_accuracy: 0.0000e+00 - val_loss: -19309390.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 135/200\n3/3 [==============================] - 0s 33ms/step - loss: -19276352.0000 - binary_accuracy: 0.0000e+00 - val_loss: -19601128.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 136/200\n3/3 [==============================] - 0s 32ms/step - loss: -19542536.0000 - binary_accuracy: 0.0000e+00 - val_loss: -19894652.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 137/200\n3/3 [==============================] - 0s 31ms/step - loss: -19951392.0000 - binary_accuracy: 0.0000e+00 - val_loss: -20190300.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 138/200\n3/3 [==============================] - 0s 40ms/step - loss: -20143892.0000 - binary_accuracy: 0.0000e+00 - val_loss: -20488730.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 139/200\n3/3 [==============================] - 0s 41ms/step - loss: -20520786.0000 - binary_accuracy: 0.0000e+00 - val_loss: -20789636.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 140/200\n3/3 [==============================] - 0s 31ms/step - loss: -20794912.0000 - binary_accuracy: 0.0000e+00 - val_loss: -21092410.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 141/200\n3/3 [==============================] - 0s 33ms/step - loss: -21125498.0000 - binary_accuracy: 0.0000e+00 - val_loss: -21397194.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 142/200\n3/3 [==============================] - 0s 31ms/step - loss: -21410244.0000 - binary_accuracy: 0.0000e+00 - val_loss: -21702680.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 143/200\n3/3 [==============================] - 0s 31ms/step - loss: -21739928.0000 - binary_accuracy: 0.0000e+00 - val_loss: -22009094.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 144/200\n3/3 [==============================] - 0s 32ms/step - loss: -21969368.0000 - binary_accuracy: 0.0000e+00 - val_loss: -22317992.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 145/200\n3/3 [==============================] - 0s 30ms/step - loss: -22338232.0000 - binary_accuracy: 0.0000e+00 - val_loss: -22629752.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 146/200\n3/3 [==============================] - 0s 31ms/step - loss: -22640784.0000 - binary_accuracy: 0.0000e+00 - val_loss: -22944306.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 147/200\n3/3 [==============================] - 0s 31ms/step - loss: -22931926.0000 - binary_accuracy: 0.0000e+00 - val_loss: -23261522.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 148/200\n3/3 [==============================] - 0s 31ms/step - loss: -23244098.0000 - binary_accuracy: 0.0000e+00 - val_loss: -23579968.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 149/200\n3/3 [==============================] - 0s 31ms/step - loss: -23568006.0000 - binary_accuracy: 0.0000e+00 - val_loss: -23900296.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 150/200\n3/3 [==============================] - 0s 31ms/step - loss: -23891574.0000 - binary_accuracy: 0.0000e+00 - val_loss: -24221914.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 151/200\n3/3 [==============================] - 0s 31ms/step - loss: -24220354.0000 - binary_accuracy: 0.0000e+00 - val_loss: -24546224.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 152/200\n3/3 [==============================] - 0s 29ms/step - loss: -24574244.0000 - binary_accuracy: 0.0000e+00 - val_loss: -24873464.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 153/200\n3/3 [==============================] - 0s 29ms/step - loss: -24860734.0000 - binary_accuracy: 0.0000e+00 - val_loss: -25203056.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 154/200\n3/3 [==============================] - 0s 30ms/step - loss: -25251378.0000 - binary_accuracy: 0.0000e+00 - val_loss: -25536134.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 155/200\n3/3 [==============================] - 0s 30ms/step - loss: -25544658.0000 - binary_accuracy: 0.0000e+00 - val_loss: -25870306.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 156/200\n3/3 [==============================] - 0s 33ms/step - loss: -25880062.0000 - binary_accuracy: 0.0000e+00 - val_loss: -26205420.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 157/200\n3/3 [==============================] - 0s 32ms/step - loss: -26203074.0000 - binary_accuracy: 0.0000e+00 - val_loss: -26542292.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 158/200\n3/3 [==============================] - 0s 32ms/step - loss: -26512438.0000 - binary_accuracy: 0.0000e+00 - val_loss: -26880984.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 159/200\n3/3 [==============================] - 0s 30ms/step - loss: -26850798.0000 - binary_accuracy: 0.0000e+00 - val_loss: -27222074.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 160/200\n3/3 [==============================] - 0s 30ms/step - loss: -27218324.0000 - binary_accuracy: 0.0000e+00 - val_loss: -27565956.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 161/200\n3/3 [==============================] - 0s 31ms/step - loss: -27545322.0000 - binary_accuracy: 0.0000e+00 - val_loss: -27912322.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 162/200\n3/3 [==============================] - 0s 31ms/step - loss: -27924160.0000 - binary_accuracy: 0.0000e+00 - val_loss: -28261510.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 163/200\n3/3 [==============================] - 0s 33ms/step - loss: -28232826.0000 - binary_accuracy: 0.0000e+00 - val_loss: -28611930.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 164/200\n3/3 [==============================] - 0s 30ms/step - loss: -28537464.0000 - binary_accuracy: 0.0000e+00 - val_loss: -28963846.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 165/200\n3/3 [==============================] - 0s 31ms/step - loss: -28920584.0000 - binary_accuracy: 0.0000e+00 - val_loss: -29317682.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 166/200\n3/3 [==============================] - 0s 32ms/step - loss: -29289286.0000 - binary_accuracy: 0.0000e+00 - val_loss: -29674910.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 167/200\n3/3 [==============================] - 0s 32ms/step - loss: -29598082.0000 - binary_accuracy: 0.0000e+00 - val_loss: -30032514.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 168/200\n3/3 [==============================] - 0s 32ms/step - loss: -30028260.0000 - binary_accuracy: 0.0000e+00 - val_loss: -30391742.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 169/200\n3/3 [==============================] - 0s 31ms/step - loss: -30375982.0000 - binary_accuracy: 0.0000e+00 - val_loss: -30753386.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 170/200\n3/3 [==============================] - 0s 34ms/step - loss: -30753968.0000 - binary_accuracy: 0.0000e+00 - val_loss: -31117490.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 171/200\n3/3 [==============================] - 0s 34ms/step - loss: -31063668.0000 - binary_accuracy: 0.0000e+00 - val_loss: -31483844.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 172/200\n3/3 [==============================] - 0s 33ms/step - loss: -31445542.0000 - binary_accuracy: 0.0000e+00 - val_loss: -31852814.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 173/200\n3/3 [==============================] - 0s 37ms/step - loss: -31778244.0000 - binary_accuracy: 0.0000e+00 - val_loss: -32223836.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 174/200\n3/3 [==============================] - 0s 35ms/step - loss: -32137122.0000 - binary_accuracy: 0.0000e+00 - val_loss: -32595078.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 175/200\n3/3 [==============================] - 0s 35ms/step - loss: -32498730.0000 - binary_accuracy: 0.0000e+00 - val_loss: -32968328.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 176/200\n3/3 [==============================] - 0s 34ms/step - loss: -32913738.0000 - binary_accuracy: 0.0000e+00 - val_loss: -33343134.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 177/200\n3/3 [==============================] - 0s 31ms/step - loss: -33312502.0000 - binary_accuracy: 0.0000e+00 - val_loss: -33719684.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 178/200\n3/3 [==============================] - 0s 36ms/step - loss: -33738312.0000 - binary_accuracy: 0.0000e+00 - val_loss: -34099356.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 179/200\n3/3 [==============================] - 0s 30ms/step - loss: -34039456.0000 - binary_accuracy: 0.0000e+00 - val_loss: -34480712.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 180/200\n3/3 [==============================] - 0s 31ms/step - loss: -34470660.0000 - binary_accuracy: 0.0000e+00 - val_loss: -34864808.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 181/200\n3/3 [==============================] - 0s 31ms/step - loss: -34885080.0000 - binary_accuracy: 0.0000e+00 - val_loss: -35251364.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 182/200\n3/3 [==============================] - 0s 31ms/step - loss: -35242980.0000 - binary_accuracy: 0.0000e+00 - val_loss: -35641052.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 183/200\n3/3 [==============================] - 0s 31ms/step - loss: -35573744.0000 - binary_accuracy: 0.0000e+00 - val_loss: -36033452.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 184/200\n3/3 [==============================] - 0s 33ms/step - loss: -36050636.0000 - binary_accuracy: 0.0000e+00 - val_loss: -36427656.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 185/200\n3/3 [==============================] - 0s 31ms/step - loss: -36370916.0000 - binary_accuracy: 0.0000e+00 - val_loss: -36824220.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 186/200\n3/3 [==============================] - 0s 32ms/step - loss: -36861968.0000 - binary_accuracy: 0.0000e+00 - val_loss: -37222860.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 187/200\n3/3 [==============================] - 0s 32ms/step - loss: -37190092.0000 - binary_accuracy: 0.0000e+00 - val_loss: -37625032.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 188/200\n3/3 [==============================] - 0s 29ms/step - loss: -37536956.0000 - binary_accuracy: 0.0000e+00 - val_loss: -38028604.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 189/200\n3/3 [==============================] - 0s 31ms/step - loss: -37993628.0000 - binary_accuracy: 0.0000e+00 - val_loss: -38432296.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 190/200\n3/3 [==============================] - 0s 35ms/step - loss: -38442396.0000 - binary_accuracy: 0.0000e+00 - val_loss: -38837132.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 191/200\n3/3 [==============================] - 0s 31ms/step - loss: -38891244.0000 - binary_accuracy: 0.0000e+00 - val_loss: -39243824.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 192/200\n3/3 [==============================] - 0s 32ms/step - loss: -39202120.0000 - binary_accuracy: 0.0000e+00 - val_loss: -39653120.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 193/200\n3/3 [==============================] - 0s 34ms/step - loss: -39632320.0000 - binary_accuracy: 0.0000e+00 - val_loss: -40064812.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 194/200\n3/3 [==============================] - 0s 31ms/step - loss: -40030512.0000 - binary_accuracy: 0.0000e+00 - val_loss: -40478316.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 195/200\n3/3 [==============================] - 0s 33ms/step - loss: -40458748.0000 - binary_accuracy: 0.0000e+00 - val_loss: -40893776.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 196/200\n3/3 [==============================] - 0s 33ms/step - loss: -40911232.0000 - binary_accuracy: 0.0000e+00 - val_loss: -41311372.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 197/200\n3/3 [==============================] - 0s 32ms/step - loss: -41304284.0000 - binary_accuracy: 0.0000e+00 - val_loss: -41730708.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 198/200\n3/3 [==============================] - 0s 31ms/step - loss: -41699972.0000 - binary_accuracy: 0.0000e+00 - val_loss: -42154572.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 199/200\n3/3 [==============================] - 0s 32ms/step - loss: -42093324.0000 - binary_accuracy: 0.0000e+00 - val_loss: -42579592.0000 - val_binary_accuracy: 0.0000e+00\nEpoch 200/200\n3/3 [==============================] - 0s 31ms/step - loss: -42589052.0000 - binary_accuracy: 0.0000e+00 - val_loss: -43006784.0000 - val_binary_accuracy: 0.0000e+00\n[[1.]\n [1.]\n [1.]\n ...\n [1.]\n [1.]\n [1.]]\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}